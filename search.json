[
  {
    "objectID": "day4.html",
    "href": "day4.html",
    "title": "day4",
    "section": "",
    "text": "The list of camp cleanup assignments has unfortunate overlaps. For example:\nActual numbers may be higher.\nSome assignments fully contain the other.\nFind them."
  },
  {
    "objectID": "day4.html#example",
    "href": "day4.html#example",
    "title": "day4",
    "section": "Example:",
    "text": "Example:\nConsider this list of assignments.\n\nexample = \"\"\"\n2-4,6-8\n2-3,4-5\n5-7,7-9\n2-8,3-7\n6-6,4-6\n2-6,4-8\n\"\"\".strip().split()\n\nWe could do this by comparing min & max. Or we could generate sets from ranges and check intersection is as large as the smaller range. But the second could struggle with very large ranges.\n\n\nCode\ndef get_assignments(data: list[str] # List of assignment pairs \"2-4,6-8\"\n                    ) -> list[list[int]]: # List of [min,max,min,max]\n    \"\"\"Split each assignment by commas and dashes.\"\"\"\n    _ = (row.replace(\"-\",\",\").split(\",\") for row in data)\n    return [[int(x) for x in row] for row in _]\n\n\n\nsource\n\nget_assignments\n\n get_assignments (data:list[str])\n\nSplit each assignment by commas and dashes.\n\n\n\n\nType\nDetails\n\n\n\n\ndata\nlist\nList of assignment pairs â€œ2-4,6-8â€\n\n\nReturns\nlist\nList of [min,max,min,max]\n\n\n\n\nassignments = get_assignments(example)\nassignments\n\n[[2, 4, 6, 8],\n [2, 3, 4, 5],\n [5, 7, 7, 9],\n [2, 8, 3, 7],\n [6, 6, 4, 6],\n [2, 6, 4, 8]]\n\n\n\n\nCode\ndef right_contains_left(row: list[int] # [min,max,min,max]\n                       )-> bool: # Right pair contains left\n    return (row[2] <= row[0]) and (row[3] >= row[1])\n\ndef left_contains_right(row: list[int] # [min,max,min,max]\n                       )-> bool: # Left pair contains right\n    return (row[0] <= row[2]) and (row[1] >= row[3])\n\ndef contains(row: list[int] # [min,max,min,max]\n            )-> bool: # One pair contains the other\n    return right_contains_left(row) or left_contains_right(row)\n\n\n\nsource\n\n\ncontains\n\n contains (row:list[int])\n\n\n\n\n\nType\nDetails\n\n\n\n\nrow\nlist\n[min,max,min,max]\n\n\nReturns\nbool\nOne pair contains the other\n\n\n\n\nsource\n\n\nleft_contains_right\n\n left_contains_right (row:list[int])\n\n\n\n\n\nType\nDetails\n\n\n\n\nrow\nlist\n[min,max,min,max]\n\n\nReturns\nbool\nLeft pair contains right\n\n\n\n\nsource\n\n\nright_contains_left\n\n right_contains_left (row:list[int])\n\n\n\n\n\nType\nDetails\n\n\n\n\nrow\nlist\n[min,max,min,max]\n\n\nReturns\nbool\nRight pair contains left\n\n\n\nTest that\n\nassert [contains(row) for row in assignments] == [False, False, False, True, True, False]"
  },
  {
    "objectID": "day4.html#get-the-data",
    "href": "day4.html#get-the-data",
    "title": "day4",
    "section": "Get the data",
    "text": "Get the data\n\nwith open(\"data/day4_input.txt\") as f:\n    data = [x.strip() for x in f.readlines()]\ndata[:3]\n\n['14-28,13-28', '72-81,82-91', '4-4,6-95']"
  },
  {
    "objectID": "day4.html#run",
    "href": "day4.html#run",
    "title": "day4",
    "section": "Run",
    "text": "Run\n\nassignments = get_assignments(data)\ncontains = [contains(row) for row in assignments]\nf\"{sum(contains):,} assignment pairs fully overlap\"\n\n'305 assignment pairs fully overlap'"
  },
  {
    "objectID": "day4.html#run-1",
    "href": "day4.html#run-1",
    "title": "day4",
    "section": "Run",
    "text": "Run\n\noverlaps = [overlap(x) for x in get_assignments(data)]\nf\"{sum(overlaps):,} assignments overlap at all.\"\n\n'811 assignments overlap at all.'"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AoC_2022",
    "section": "",
    "text": "This is my first year of AoC, and Iâ€™ve decided to use it to practice with nbdev to automatically generate modules and documentation from my notebooks.\nIâ€™ll probably evolve my organization as I go. I did Day 1 with a regular python module and that made sense to put each day in its own folder with data as input.txt. But I think with nbdev it makes sense to have the usual nbs folder for all the notebooks, one per day. In that case Iâ€™ll put the data in data/dayX_input.txt. Like so:\nNot sure the AoC badges are working quite right? Do I have to update manually?"
  },
  {
    "objectID": "index.html#explore",
    "href": "index.html#explore",
    "title": "AoC_2022",
    "section": "Explore",
    "text": "Explore\nPlease feel free to:\n\nBrowse the lovely documentation automatically generated by nbdev, or\nView the code."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "AoC_2022",
    "section": "How to use",
    "text": "How to use\nNbdev creates python modules from notebooks, so if you clone the repo you can call exported functions using the AoC_2022 package.\n\nGet the code. If using the GitHub CLI:\n\ngh repo clone ctwardy/AoC_2022\n\nInstall the package locally so AoC_2022 is in your namespace.\n\npip install -e '.[dev]'\nThen you can do something like this:\n\nimport AoC_2022.day2 as day2\n\nwith open(\"data/day2_input.txt\") as f:\n    data = [day2.rps_decode(x.strip()) for x in f.readlines()]\nday2.score_strategy(data)\n\n13022"
  },
  {
    "objectID": "index.html#day-1-calorie-counting",
    "href": "index.html#day-1-calorie-counting",
    "title": "AoC_2022",
    "section": "Day 1: Calorie Counting",
    "text": "Day 1: Calorie Counting\nWait! Itâ€™s December already? OK, just write Python using nano and commandline. That wasnâ€™t so bad. Iâ€™m not fast, but it was straightforward."
  },
  {
    "objectID": "index.html#day-2-rock-paper-scissors",
    "href": "index.html#day-2-rock-paper-scissors",
    "title": "AoC_2022",
    "section": "Day 2: Rock Paper Scissors",
    "text": "Day 2: Rock Paper Scissors\nOK, installed the new nbdev. Used str.translate to change from ABC to RPS. In Part 2 that needed an extra step to look at the opponents move, but strategy dictionary seemed an okay approach."
  },
  {
    "objectID": "index.html#day-3-rucksack-reorg",
    "href": "index.html#day-3-rucksack-reorg",
    "title": "AoC_2022",
    "section": "Day 3: Rucksack Reorg",
    "text": "Day 3: Rucksack Reorg\nLearning more nbdev features like docments and code-folding. I think docments make the function declaration slightly uglier, but the generated docs are amazing. Worth it.\nProgramming: got to use functools.reduce.\nNbdev: Local docs were pretty easy. Spent hours troubleshooting on GitHub. Docs didnâ€™t like index.ipynb using ../data/ for file location. Solved by making nbs/data -> ../data and then referring to data/. Later saw this in the docs:\n\n\n\n\n\n\nNote\n\n\n\nAll documentation related files should be included in your nbs_path, and all paths should be relative to it. â€¦"
  },
  {
    "objectID": "index.html#day-4-camp-cleanup",
    "href": "index.html#day-4-camp-cleanup",
    "title": "AoC_2022",
    "section": "Day 4: Camp Cleanup",
    "text": "Day 4: Camp Cleanup\nWas able to follow the Day 3 nbdev template. Solution was straightforward, but all told still me a bit more than an hour. Hm. Over 90 minutes after adding this section to the README (index.ipynb). Nbdev makes documentation tempting. Thatâ€™s not necessarily a bad thing.\nNbdev: nbdev_prep caught a leftover day3 cell at the bottom of my day4 notebook. Cool. But after fixing, the running preview still didnâ€™t have day4. But stopping and re-running did. Guess thatâ€™s a thing."
  },
  {
    "objectID": "index.html#day-5-supply-stacks",
    "href": "index.html#day-5-supply-stacks",
    "title": "AoC_2022",
    "section": "Day 5: Supply Stacks",
    "text": "Day 5: Supply Stacks\nThis took me surprisingly long. I had the example parsed in 45 minutes, but then realized move() would be easier with stacks, and iterating on that entered a regress. Once the example ran, Part 1 followed with one tweak, then Part 2 needed only a quick rewrite of move().\nNbdev: Worked locally but GitHub CI still failed. Hoo boy.\n\nimport numpy but numpy not found. Either add numpy dependency to settings.ini or drop. Not using yet. Dropped.\nI had used 3.10 type hints like int|str. But GH was using 3.9 so this failed in CI. Bumped settings.ini to specify 3.10.\nGH still using 3.9, which now failed to satisfy min version.\nChanged setup.py to force 3.10. Same error.\nModify .github/workflows/test.yml per this forum post. Same type hints error.\nGo back to min of 3.8, and use from __future__ import annotations. Supposed to work. Same error.\nAdd 3.10 to .github/workflows/deploy.yml as well. Kill __future__. Success.\n\nCombo of something not quite working in nbdev config, and me not knowing how GitHub CI worked. Better now, I think."
  },
  {
    "objectID": "index.html#day-6-tuning-trouble",
    "href": "index.html#day-6-tuning-trouble",
    "title": "AoC_2022",
    "section": "Day 6: Tuning Trouble",
    "text": "Day 6: Tuning Trouble\nThis one was much easier. About 7-10 minutes to write up the example, and another 5-10 minutes to solve. It was quick to see that len(set(s)) == n would do it. The rest was just typing and fixing.\nNbdev: ran find, but nbdev_preview hit a weird glitch where it forgot examples in the cell defining get_pos_firstn_uniq(), despite knowing it in the previous or next cell. So I just split the cell."
  },
  {
    "objectID": "index.html#day-7-no-space-on-device",
    "href": "index.html#day-7-no-space-on-device",
    "title": "AoC_2022",
    "section": "Day 7: No space on device",
    "text": "Day 7: No space on device\nNeeded recursive ops to make & query a directory tree. Started with a simple class, then two helpers. Then noticed calls could be simpler if I defined magic methods like __getitem__ and __iter__. Realized dirs needed to track parent which provided full path and depth. Recursion took some tuning. Lessons learned:\n\nSoftware Eng: Beware copy/paste! Lost hours because call to Part1 had the wrong input. ðŸ¤¦â€â™‚ï¸\nSoftware Eng: Incremental tests helped. Also, donâ€™t be clever.\nClasses: Directory methods can use isinstance(arg, Directory): itâ€™s not defined yet, but it will be before use. Clearer and more correct than if type(x) == type(me). But until 3.11 we canâ€™t use Directory as a type hint inside Directory.\nDefault mutable! Declaring _kids = [] as a @dataclass is a default mutable in __init__. Bad!"
  },
  {
    "objectID": "day7.html",
    "href": "day7.html",
    "title": "day7",
    "section": "",
    "text": "This one is more complicated. Going to start at the end of the description and work back.\nOK, I did, but as I worked back I kept adding things to the core classes, so it doesnâ€™t start as simple as I did.\nWe will need to: find all of the directories with a total size of at most 100,000, then calculate the sum of their total sizes. In the example above, these directories are a and e; the sum of their total sizes is 95,437 (94,853 + 584). (As in this example, this process can count files more than once!)"
  },
  {
    "objectID": "day7.html#base-fileobj-file",
    "href": "day7.html#base-fileobj-file",
    "title": "day7",
    "section": "Base FileObj & File",
    "text": "Base FileObj & File\nJust names and sizes and __str__.\n\n\nCode\nfrom dataclasses import dataclass, field\n\n@dataclass\nclass FileObj():\n    \"\"\"Base class for File & Directory. Has a name\"\"\"\n    name: str   # Name of the file or dir.\n        \n@dataclass\nclass File(FileObj):\n    \"\"\"Files have name and size\"\"\"\n    size: int   # Size of a file is given\n        \n    def __str__(me):\n        return f\"{me.name} (file, size={me.size})\"\n\n\n\nsource\n\nFile\n\n File (name:str, size:int)\n\nFiles have name and size\n\nsource\n\n\nFileObj\n\n FileObj (name:str)\n\nBase class for File & Directory. Has a name\n\ni = File(\"i\", 584)\nf = File(\"f\", 29116)\ng = File(\"g\", 2557)\nh = File(\"h.lst\", size=62596)\nfiles = [i, f, g, h]\n\nassert f\"{i}\" == \"i (file, size=584)\""
  },
  {
    "objectID": "day7.html#directory",
    "href": "day7.html#directory",
    "title": "day7",
    "section": "Directory",
    "text": "Directory\nDirectories compute their .size from their members. This is naturally recursive. ðŸ˜Š\nThis started really simple & grew as I needed methods later. Now has:\n\nparent so we can build path and know depth.\n\nStarts as None.\nGets assigned when our parent adds us. (During __setitem__ now.)\nHelps __str__ get indents right\nEliminates need to build separate list of dirs during input.\n\nProvides [] getting and setting items in dir.\n\nImplementation changed from list to dict.\n\nAdded subdirs to get just the kids that are dirs.\nEvicted a recursive version of that to a helper (below)\n\n\n\n\n\n\n\nAlert\n\n\n\nInitializing _kids: [] turns all Directory into Ender chests. Beware the default-mutable!\n\n\n\n\n\n\n\n\nAlert\n\n\n\nSolutions that worked in Example failed in Part 1 because (a) data has multiple dirs of same name (in different locations), & (b) I ran the solution on the wrong arg.\n\n\nDoing (b) definitely caused a too-low error. I think it was (a) that caused the too-high error. But I didnâ€™t find (b) until the end and by then fixing that fixed all.\n\n\nCode\n@dataclass\nclass Directory(FileObj):\n    \"\"\"Directories have kids (files or dirs), and PARENT\"\"\"\n    parent: FileObj=None  # My parent dir. Set when I'm appended.\n    _kids: dict[str: FileObj] = field(default_factory=dict)\n    \n    @property\n    def size(me):\n        \"\"\"Dir size is sum of kids' sizes.\"\"\"\n        return sum(f.size for f in me._kids.values())\n    \n    @property\n    def path(me) -> str:\n        \"\"\"The path/to/me/.  <- Note slash placement.\"\"\"\n        try:\n            return f\"{me.parent.path}{me.name}/\"\n        except AttributeError:\n            return f\"{me.name}/\"\n        \n    @property\n    def depth(me):\n        \"\"\"How far down the tree am me?\"\"\"\n        return me.path.count(\"/\") - me.path.count(\"//\") - 1\n    \n    @property\n    def subdirs(me):\n        \"\"\"My kids what could has kids. Not files.\"\"\"\n        return [x for x in me if isinstance(x, Directory)]\n        \n    def append(me, obj: FileObj) -> None:\n        \"\"\"Shortcut: just me.append(e) instead of me[e.name] = e.\"\"\"\n        me[obj.name] = obj\n        \n    def __str__(me):\n        \"\"\"Indent formatted for pretty-printing: whole tree below me.\"\"\"\n        indent = \"  \" * me.depth\n        head = f\"{me.name} (dir, size={me.size})\"\n        tail = f\"\\n\".join(f\"{indent} - {val}\" for val in me)  # uses __iter__\n        return f\"{head}\\n{tail}\"\n    \n    def __iter__(me):\n        \"\"\"Return iterator of objects (not names!) in _kids.\"\"\"\n        return iter(me._kids.values())\n    \n    def __getitem__(me, name: str) -> FileObj:\n        \"\"\"Get member FileObj by name. Or die.\"\"\"\n        return me._kids[name]\n\n    def __setitem__(me, name: str, arg: FileObj) -> None:\n        \"\"\"Add {name: arg} to _kids; if arg is dir, set arg.parent->me.\"\"\"\n        me._kids[name] = arg\n        if isinstance(arg, Directory):\n            if arg.parent is not None:\n                raise(ValueError, \"We are stealing someone else's kid!\")\n            arg.parent = me\n\n\n\nsource\n\nDirectory\n\n Directory (name:str, parent:__main__.FileObj=None,\n            _kids:dict[slice(<class'str'>,<class'__main__.FileObj'>,None)]\n            =<factory>)\n\nDirectories have kids (files or dirs), and PARENT\nTest recursive size in 2-item case, and show __str__.\n\ne = Directory(\"e\")\ne.append(i)\nassert e.size == i.size == 584\nassert e[\"i\"] == i\nassert e.depth == 0\nprint(e)\n\ne (dir, size=584)\n - i (file, size=584)\n\n\nEnsure new Directory is independent! (Catch default mutable error.)\n\nf = File(\"f\", 29116)\nroot = Directory(\"/\")\nroot.append(f)\nassert root.size == f.size == 29116\nassert root.depth == 0\nprint(root)\n\n/ (dir, size=29116)\n - f (file, size=29116)\n\n\nTest recursive sum, depth, and indented __str__.\n\na = Directory(\"a\")\nroot.append(a)\ng, h = File(\"g\", 2557), File(\"h.lst\", size=62596)\nf2 = File(\"f\", 512) # <- Another file named f!\nassert f2 is not f\n\nfor item in [e, f2, g, h, Directory(\"k\")]:\n    a.append(item)\n\nprint(root)\nassert a.size == 66249\nassert root.size == f.size + a.size\nassert root.depth == 0\nassert a.depth == 1\nassert e.depth == 2\nassert a[\"k\"].depth == 2\n\n/ (dir, size=95365)\n - f (file, size=29116)\n - a (dir, size=66249)\n   - e (dir, size=584)\n     - i (file, size=584)\n   - f (file, size=512)\n   - g (file, size=2557)\n   - h.lst (file, size=62596)\n   - k (dir, size=0)\n\n\n\nTest the subdirs property at two depths.\n\nassert [x.name for x in root.subdirs] == ['a']\nassert [x.name for x in a.subdirs] == ['e', 'k']"
  },
  {
    "objectID": "day7.html#get-all-subdirs",
    "href": "day7.html#get-all-subdirs",
    "title": "day7",
    "section": "Get all subdirs",
    "text": "Get all subdirs\n\nThis is basically a filtered depth-first traversal.\n\nThis used to return dir objects. Changed to (name, size) tuples while trying to track down Part1 error that turned out to be something else entirely. Could change back but, eh.\n\n\nCode\ndef get_all_subdirs(start: Directory) -> list[Directory]:\n    \"\"\"Return flat list of (name, size) for _all_ dirs under `start` dir.\"\"\"\n    my_dirs = [(x.name, x.size) for x in start.subdirs]\n    for _dir in start.subdirs:\n        my_dirs.extend(get_all_subdirs(_dir))\n    return my_dirs\n\n\n\nsource\n\nget_all_subdirs\n\n get_all_subdirs (start:__main__.Directory)\n\nReturn flat list of (name, size) for all dirs under start dir.\n\nget_all_subdirs(root)\n\n[('a', 66249), ('e', 584), ('k', 0)]\n\n\n\nassert [x[0] for x in get_all_subdirs(root)] == ['a', 'e', 'k']\n\nOK, looks good! Now need to read the data."
  },
  {
    "objectID": "day7.html#parse-the-dirs",
    "href": "day7.html#parse-the-dirs",
    "title": "day7",
    "section": "Parse the dirs",
    "text": "Parse the dirs\n\n\nCode\ndef get_dirs(commands: list[str]) -> Directory:\n    \"\"\"Create dir tree from '/'. Return all dirs\"\"\"\n    root = Directory(\"/\")\n    dirstack = [root]\n\n    for i, line in enumerate(commands):\n        cur_dir = dirstack[-1]\n        match line.split():\n            case (\"$\", \"ls\"):\n                continue\n            case (\"dir\", dirname):\n                try:\n                    cur_dir[dirname]  # Should fail, unless twice ls same dir\n                    print(\"*********** {dirname} already in {cur_dir.name}!\")\n                except KeyError:\n                    cur_dir.append(Directory(dirname))\n            case (\"$\", \"cd\", dirname):\n                match dirname:\n                    case \"/\":\n                        dirstack = [root]\n                    case \"..\":\n                        dirstack.pop()\n                    case _: \n                        dirstack.append(cur_dir[dirname])\n                depth = len(dirstack) - 1\n                print(f'{\"âš\" * depth}\\tfrom cd {dirname}\\t in line {i}')\n            case (size, name):\n                f = File(name, int(size))\n                cur_dir.append(f)\n            case _:\n                raise ValueError(f\"Unrecognized line: '{line}'\")\n    return root\n            \ndirs = get_dirs(example)\n\n\n    from cd /    in line 0\nâš   from cd a    in line 6\nâšâš  from cd e    in line 12\nâš   from cd ..   in line 15\n    from cd ..   in line 16\nâš   from cd d    in line 17\n\n\n\nsource\n\nget_dirs\n\n get_dirs (commands:list[str])\n\nCreate dir tree from â€˜/â€™. Return all dirs\n\n## Test the parsing\n\n\nprint(dirs)\nassert len(str(dirs).split(\"\\n\")) == 14\n\n/ (dir, size=48381165)\n - a (dir, size=94853)\n   - e (dir, size=584)\n     - i (file, size=584)\n   - f (file, size=29116)\n   - g (file, size=2557)\n   - h.lst (file, size=62596)\n - b.txt (file, size=14848514)\n - c.dat (file, size=8504156)\n - d (dir, size=24933642)\n   - j (file, size=4060174)\n   - d.log (file, size=8033020)\n   - d.ext (file, size=5626152)\n   - k (file, size=7214296)\n\n\nWeâ€™re told: > The total size of directory e is 584 because it contains a single file i of size 584 and no other directories. The directory a has total size 94853 because it contains files f (size 29116), g (size 2557), and h.lst (size 62596), plus file i indirectly (a contains e which contains i). Directory d has total size 24933642. As the outermost directory, / contains every file. Its total size is 48381165, the sum of the size of every file.\n\nassert dirs['a']['e'].size == 584\nassert dirs['a'].size == 94853\nassert dirs['d'].size == 24933642\nassert dirs.size == 48381165\n\n\nToDo Special case dirs[\"/\"] to get self?"
  },
  {
    "objectID": "day7.html#with-total-size-100k",
    "href": "day7.html#with-total-size-100k",
    "title": "day7",
    "section": "With total size â‰¤ 100K",
    "text": "With total size â‰¤ 100K\nGoal: > To begin, find all of the directories with a total size of at most 100,000, then calculate the sum of their total sizes. In the example above, these directories are a and e; the sum of their total sizes is 95,437 (94,853 + 584). (As in this example, this process can count files more than once!)\nThe code below would be clearer if get_all_subdirs returned objects instead of (name, size) tuples.\n\n\nCode\ndef sum_cutoff(start: Directory, cutoff=100_000) -> int:\n    \"\"\"Return sum of sizes for dirs with size < cutoff.\"\"\"\n    subdirs = get_all_subdirs(start)\n    sizes = [x[1] for x in subdirs if x[1] < 100_000]\n    return sum(x for x in sizes if x <= cutoff)\n\n\n\nsource\n\nsum_cutoff\n\n sum_cutoff (start:__main__.Directory, cutoff=100000)\n\nReturn sum of sizes for dirs with size < cutoff.\n\nassert sum_cutoff(dirs) == 95437"
  },
  {
    "objectID": "day7.html#get-the-data",
    "href": "day7.html#get-the-data",
    "title": "day7",
    "section": "Get the data",
    "text": "Get the data\n\nwith open(f\"data/{NAME}_input.txt\") as f:\n    data = f.read()\ndata = data.strip().split(\"\\n\")\n\nExamine the data - because it broke code that worked on the example.\n\nprint(f\"Data has {len(data)} commands. First few:\")\nprint(\"\\n\".join(x for x in data[:10]))\nlines_with_dir = [x for x in data if x.startswith('dir')]\nprint(f\"There are {len(lines_with_dir)} lines with 'dir'.\")\n\nData has 1014 commands. First few:\n$ cd /\n$ ls\ndir blgtdv\ndir dbrfcz\ndir fvspj\ndir hbjmndt\ndir hzg\ndir jpjgdm\ndir mtd\ndir pcpf\nThere are 182 lines with 'dir'.\n\n\nNote that names get reused!\n\nfvspj = [row for row in data if \"cd fvspj\" in row]\nfvspj2 = [row for row in data if \"dir fvspj\" in row]\nprint(f\"There are {len(fvspj)} rows with 'cd fvspj'!\")\nprint(f\"There are {len(fvspj2)} rows with 'dir fvspj'!\")\n\nThere are 13 rows with 'cd fvspj'!\nThere are 13 rows with 'dir fvspj'!"
  },
  {
    "objectID": "day7.html#run",
    "href": "day7.html#run",
    "title": "day7",
    "section": "Run",
    "text": "Run"
  },
  {
    "objectID": "day7.html#run-get_dirs-and-check",
    "href": "day7.html#run-get_dirs-and-check",
    "title": "day7",
    "section": "Run get_dirs and check",
    "text": "Run get_dirs and check\n\npart1_tree = get_dirs(data)\n\nScreenshot from output:\n\n\n\nimage.png\n\n\n\nprint(part1_tree)\n\nScreenshot from output:\n\n\n\nimage.png"
  },
  {
    "objectID": "day7.html#run-get_all_subdirs-and-sum_cutoff",
    "href": "day7.html#run-get_all_subdirs-and-sum_cutoff",
    "title": "day7",
    "section": "Run get_all_subdirs and sum_cutoff",
    "text": "Run get_all_subdirs and sum_cutoff\n\npart1_subdirs = get_all_subdirs(part1_tree)\ndata_dirs = [x for x in data if x.startswith(\"$ cd\") and not x.endswith(\"..\")]\nn_getall = len(part1_subdirs)\nf\"{n_getall} from get_all_subdirs; {len(data)} commands, of which {len(data_dirs)} cd to dir.\"\n\n'182 from get_all_subdirs; 1014 commands, of which 183 cd to dir.'\n\n\n\nassert n_getall <= len(data_dirs)\nassert len(data_dirs) < len(data)\n\nAnswer!\n\nsum_cutoff(part1_tree)\n\n1667443\n\n\nCorrect answer for Part1: 1,667,443.\n\nGuess 1: 66833 -> Too low\nGuess 2: 214,201,382 -> Too high Oh gosh yes, itâ€™s larger than size of /!\n\nDâ€™oh! While some cleanups of the classes and functions no doubt helped, the core problem was:\nsum_cutoff(root)\nRather than\nsum_cutoff(part1_tree)\nCopy/paste error: â€œrootâ€ was the example."
  },
  {
    "objectID": "day2.html",
    "href": "day2.html",
    "title": "day2",
    "section": "",
    "text": "Decode the elfâ€™s RPS strategy and score the game. Strategy data will be in two columns like:\nThis strategy guide predicts opponent will play Rock (A), then Paper (B), then Scissors (C). It recommends you play: * Paper (Y) two win with score of 2 for Paper + 6 for win = 8. * Rock (X) with score of 1 for Rock + 0 for loss = 1. * Scissors (Z) for score of 3 for Scissors + 3 for draw = 6. * Total Score = 15\nSolution sketch:"
  },
  {
    "objectID": "day2.html#get-the-data",
    "href": "day2.html#get-the-data",
    "title": "day2",
    "section": "Get the data",
    "text": "Get the data\nDecode both moves to R, P, S. Keep as a two-letter string like â€œRPâ€.\n\nRPS_CODE = str.maketrans(\"ABCXYZ\", \"RPSRPS\", \" \")\ndef rps_decode(data: str) -> str:\n    return str.translate(data, RPS_CODE)\n\n\nwith open(\"../data/day2_input.txt\") as f:\n    data = [x.strip()\n             .translate(RPS_CODE)\n             for x in f.readlines()]\ndata[:5]\n\n['PP', 'SS', 'SP', 'SP', 'RR']"
  },
  {
    "objectID": "day2.html#define-the-scoring",
    "href": "day2.html#define-the-scoring",
    "title": "day2",
    "section": "Define the scoring",
    "text": "Define the scoring\n\nsource\n\nscore_strategy\n\n score_strategy (strategy:list[str])\n\n\nsource\n\n\nscore_round\n\n score_round (moves:str)"
  },
  {
    "objectID": "day2.html#test-using-the-example",
    "href": "day2.html#test-using-the-example",
    "title": "day2",
    "section": "Test using the example",
    "text": "Test using the example\n\nassert score_round(\"RP\") == 8   # win + 2\nassert score_round(\"RR\") == 4   # draw + 1\nassert score_round(\"RS\") == 3   # lose + 3\n\ntest = [\"A Y\", \"B X\", \"C Z\"]\ntest = [x.translate(RPS_CODE) for x in test]\nassert [score_round(x) for x in test] == [8, 1, 6]\nassert score_strategy(test) == 15"
  },
  {
    "objectID": "day2.html#run-on-the-data",
    "href": "day2.html#run-on-the-data",
    "title": "day2",
    "section": "Run on the data",
    "text": "Run on the data\n\nscore_strategy(data)\n\n11841"
  },
  {
    "objectID": "day2.html#redefine-the-coding",
    "href": "day2.html#redefine-the-coding",
    "title": "day2",
    "section": "Redefine the coding",
    "text": "Redefine the coding\n\nsource\n\nget_plan\n\n get_plan (strat:str)\n\nReturn dict of resposes for 1-letter strat\n\nsource\n\n\nrps_decode\n\n rps_decode (code:str)\n\nConvert coded â€˜A Xâ€™ type string to â€˜RSâ€™ type string."
  },
  {
    "objectID": "day2.html#test-using-example",
    "href": "day2.html#test-using-example",
    "title": "day2",
    "section": "Test using example",
    "text": "Test using example\n\ntest = [\"A Y\", \"B X\", \"C Z\"]\ntest = [rps_decode(x) for x in test]\nassert [score_round(x) for x in test] == [4, 1, 7]\nassert score_strategy(test) == 12"
  },
  {
    "objectID": "day2.html#run-on-data",
    "href": "day2.html#run-on-data",
    "title": "day2",
    "section": "Run on data",
    "text": "Run on data\n\nwith open(\"../data/day2_input.txt\") as f:\n    data = [rps_decode(x.strip()) for x in f.readlines()]\nscore_strategy(data)\n\n13022"
  },
  {
    "objectID": "day6.html",
    "href": "day6.html",
    "title": "day6",
    "section": "",
    "text": "Detect a start-of-packet marker: a sequence of four characters that are all different.\nIdentify the first position where the four most recently received characters were all different.\nHow many characters need to be processed before the first start-of-packet marker is detected?"
  },
  {
    "objectID": "day6.html#get-the-data",
    "href": "day6.html#get-the-data",
    "title": "day6",
    "section": "Get the data",
    "text": "Get the data\n\ninput_name = f\"data/{NAME}_input.txt\"\nwith open(f\"data/{NAME}_input.txt\") as f:\n    data = f.read()\ndata[:10]\n\n'pwjwljjjvq'"
  },
  {
    "objectID": "day6.html#run",
    "href": "day6.html#run",
    "title": "day6",
    "section": "Run",
    "text": "Run\n\nget_pos_firstn_uniq(data)\n\n1235"
  },
  {
    "objectID": "day3.html",
    "href": "day3.html",
    "title": "day3",
    "section": "",
    "text": "Each rucksack has two compartments. Items of a type should go into exactly one. Packing elf failed for exactly one item per rucksack.\nInput: items now in each rucksack, 52 types a-zA-Z. First half in compartment 1, second in 2.\nRead on."
  },
  {
    "objectID": "day3.html#example",
    "href": "day3.html#example",
    "title": "day3",
    "section": "Example:",
    "text": "Example:\nSuppose we have the following list of 6 pack contents:\n\nexample = \"\"\"\nvJrwpWtwJgWrhcsFMMfFFhFp\njqHRNqRjqzjGDLGLrsFMfFZSrLrFZsSL\nPmmdzqPrVvPwwTWBwg\nwMqvLMZHhHMvwLHjbvcjnnSBnvTQFn\nttgJtRGJQctTZtZT\nCrZsJsPPZsGzwwsLwLmpwMDw\n\"\"\"\n\npacks_ex = example.split()\n\nWe can get their lengths:\n\nlengths = [len(x) for x in packs_ex]\nlengths\n\n[24, 32, 18, 30, 16, 24]\n\n\nEach pack is evenly divided into two comparments:\n\n\nCode\ndef get_compartments(packs: list[str] # List of pack contents like ['vJrwpWtw', ...]\n                    ) -> list[tuple]: # Split each pack like ('vJrw', 'pWtw')\n    \"\"\"Split each pack down the middle.\"\"\"\n    lengths = [len(x) for x in packs]\n    return [(pack[:lengths[i]//2], pack[lengths[i]//2:]) \n                for i, pack in enumerate(packs)]\n\nget_compartments(packs_ex)\n\n\n[('vJrwpWtwJgWr', 'hcsFMMfFFhFp'),\n ('jqHRNqRjqzjGDLGL', 'rsFMfFZSrLrFZsSL'),\n ('PmmdzqPrV', 'vPwwTWBwg'),\n ('wMqvLMZHhHMvwLH', 'jbvcjnnSBnvTQFn'),\n ('ttgJtRGJ', 'QctTZtZT'),\n ('CrZsJsPPZsGz', 'wwsLwLmpwMDw')]\n\n\n\nsource\n\nget_compartments\n\n get_compartments (packs:list[str])\n\nSplit each pack down the middle.\n\n\n\n\nType\nDetails\n\n\n\n\npacks\nlist\nList of pack contents like [â€˜vJrwpWtwâ€™, â€¦]\n\n\nReturns\nlist\nSplit each pack like (â€˜vJrwâ€™, â€˜pWtwâ€™)\n\n\n\nNote each pack has precisely one item that is in both compartments:\n\n\nCode\ndef get_shared(compartments: list[tuple] # ('vJrw','pWtw')\n              ) -> list[str]: # Single char like 'w' here.\n    \"\"\"Find the shared item in each pack: same in both compartments.\"\"\"\n    return [set(left).intersection(right).pop()\n            for left, right in compartments]\n\nshared = get_shared(get_compartments(packs_ex))\nshared\n\n\n['p', 'L', 'P', 'v', 't', 's']\n\n\n\nsource\n\n\nget_shared\n\n get_shared (compartments:list[tuple])\n\nFind the shared item in each pack: same in both compartments.\n\n\n\n\nType\nDetails\n\n\n\n\ncompartments\nlist\n(â€˜vJrwâ€™,â€˜pWtwâ€™)\n\n\nReturns\nlist\nSingle char like â€˜wâ€™ here.\n\n\n\nAnd each item has a priority:\n   a..z -> 1..26\n   A..Z -> 27..52\n\n\nCode\nBASE_LOWER = ord(\"a\") - 1    # 1..26\nBASE_UPPER = ord(\"A\") - 27   # 27..52\n\ndef priority(char: str # Single char like 'w'\n            ) -> int: # Priority 1..52\n    \"\"\"Return priority 1..52 of item in pack.\"\"\"\n    if char.lower() == char:\n        return ord(char) - BASE_LOWER\n    return ord(char) - BASE_UPPER\n\n\n\nsource\n\n\npriority\n\n priority (char:str)\n\nReturn priority 1..52 of item in pack.\n\n\n\n\nType\nDetails\n\n\n\n\nchar\nstr\nSingle char like â€˜wâ€™\n\n\nReturns\nint\nPriority 1..52\n\n\n\nTest that\n\nassert [priority(x) for x in shared] == [16, 38, 42, 22, 20, 19]"
  },
  {
    "objectID": "day3.html#get-the-data",
    "href": "day3.html#get-the-data",
    "title": "day3",
    "section": "Get the data",
    "text": "Get the data\nDecode both moves to R, P, S. Keep as a two-letter string like â€œRPâ€.\n\nwith open(\"../data/day3_input.txt\") as f:\n    packs1 = [x.strip() for x in f.readlines()]\npacks1[:5]\n\n['CjhshBJCSrTTsLwqwqwb',\n 'GtmnFHlDfcpHbLZjtTTRLWwb',\n 'fDfNHHjVFNvvrvVBJJdS',\n 'PPWvWQjPhrPQwlMWJJdMDGbJTdCJ',\n 'rsqsStgNNggBNBZHSrJGdJdCFRRZCFbGbTdJ']"
  },
  {
    "objectID": "day3.html#run",
    "href": "day3.html#run",
    "title": "day3",
    "section": "Run",
    "text": "Run\n\npriorities = [priority(x) for x in\n    get_shared(get_compartments(packs1))]\nsum(priorities)\n\n7766"
  },
  {
    "objectID": "day3.html#find-badge-for-a-group",
    "href": "day3.html#find-badge-for-a-group",
    "title": "day3",
    "section": "Find badge for a group",
    "text": "Find badge for a group\n\n\nCode\nfrom typing import Collection\nfrom functools import reduce\n\ndef intersect(left: Collection, # Items in first group\n              right: Collection # Items in second group\n             ) -> str: # Items common to both \n    \"\"\"Find set intersection btw two args.\"\"\"\n    return set(left).intersection(right)\n\ndef get_badge(group: list[str] # List of item names\n             ) -> str: # The single item common to all\n    \"\"\"Find common item. Assumes there is precisely 1.\"\"\"\n    return reduce(intersect, group).pop()\n\n\n\nsource\n\nget_badge\n\n get_badge (group:list[str])\n\nFind common item. Assumes there is precisely 1.\n\n\n\n\nType\nDetails\n\n\n\n\ngroup\nlist\nList of item names\n\n\nReturns\nstr\nThe single item common to all\n\n\n\n\nsource\n\n\nintersect\n\n intersect (left:Collection, right:Collection)\n\nFind set intersection btw two args.\n\n\n\n\nType\nDetails\n\n\n\n\nleft\nCollection\nItems in first group\n\n\nright\nCollection\nItems in second group\n\n\nReturns\nstr\nItems common to both\n\n\n\n\nassert get_badge(packs_ex[:3]) == \"r\"\nassert get_badge(packs_ex[3:6]) == \"Z\""
  },
  {
    "objectID": "day3.html#find-groups-from-packlist",
    "href": "day3.html#find-groups-from-packlist",
    "title": "day3",
    "section": "Find groups from packlist",
    "text": "Find groups from packlist\n\n\nCode\ndef get_groups(packs: list[str] # List of all packs\n              ) -> list[list]:  # Divided into lists of 3\n    \"\"\"Split packlist into groups of 3\"\"\"\n    return [[packs[i], packs[i+1], packs[i+2]]\n            for i in range(0, len(packs), 3)]\n\n\n\nsource\n\nget_groups\n\n get_groups (packs:list[str])\n\nSplit packlist into groups of 3\n\n\n\n\nType\nDetails\n\n\n\n\npacks\nlist\nList of all packs\n\n\nReturns\nlist\nDivided into lists of 3\n\n\n\n\nget_groups(packs_ex)\n\n[['vJrwpWtwJgWrhcsFMMfFFhFp',\n  'jqHRNqRjqzjGDLGLrsFMfFZSrLrFZsSL',\n  'PmmdzqPrVvPwwTWBwg'],\n ['wMqvLMZHhHMvwLHjbvcjnnSBnvTQFn',\n  'ttgJtRGJQctTZtZT',\n  'CrZsJsPPZsGzwwsLwLmpwMDw']]\n\n\n\nassert [get_badge(group)\n        for group in get_groups(packs_ex)] == ['r','Z']"
  },
  {
    "objectID": "day3.html#run-1",
    "href": "day3.html#run-1",
    "title": "day3",
    "section": "Run",
    "text": "Run\n\nbadges = [get_badge(group) \n          for group in get_groups(packs1)]\nsum([priority(x) for x in badges])\n\n2415"
  },
  {
    "objectID": "day5.html",
    "href": "day5.html",
    "title": "day5",
    "section": "",
    "text": "The elves want to know which crate will end up on top of each stack.\nThe input is a picture of the crates and a list of crane instructions for moving them. See below."
  },
  {
    "objectID": "day5.html#starting-position",
    "href": "day5.html#starting-position",
    "title": "day5",
    "section": "Starting Position",
    "text": "Starting Position\n\n# Split so it's like readlines.\nstart = example.split(\"\\n\")\n# Confirm the blanks go to the end of row\nassert start[0][9] == \" \"\n\n\n\nCode\ndef get_state(rowdata: list[str]  # Data as if readlines\n            )-> list[list[str]]:  # Row-oriented list, top-down\n    ncols = len(rowdata[0])\n    nrows = rowdata.index(\"\") - 1\n    return [[row[i] \n             for i in range(1, ncols, 4)]\n            for row in rowdata[:nrows]]\n\ndef print_state(state: list[list[str]])-> None:\n    \"\"\"Print a picture of the state. Stacks should be vertical.\"\"\"\n    print(\"\\n\".join(\" \".join(x) for x in state))\n    print(\" \".join(f\"{i+1}\" for i in range(len(state[0]))))\n\n\n\nsource\n\nprint_state\n\n print_state (state:list[list[str]])\n\nPrint a picture of the state. Stacks should be vertical.\n\nsource\n\n\nget_state\n\n get_state (rowdata:list[str])\n\n\n\n\n\nType\nDetails\n\n\n\n\nrowdata\nlist\nData as if readlines\n\n\nReturns\nlist\nRow-oriented list, top-down\n\n\n\n\nstate = get_state(start)\nprint_state(state)\n\n  D  \nN C  \nZ M P\n1 2 3\n\n\nBut it became clear Iâ€™d want that as actual stacks.\nConvert picture to list of stacks, removing blanks. If we kept the blanks this would be a simple .T transpose in numpy, but we want ragged stacks or we will stack crates on air.\n\n\nCode\nfrom collections import deque\n\ndef stackify(state: list[list] # Crate state in visual format\n            )-> list[deque]:   # State as list of stacks, no blanks\n    \"\"\"Convert row-oriented input to compact stacks, top=right.\"\"\"\n    nrows, ncols = len(state), len(state[0])\n    return [deque([state[row][col] for row in range(nrows-1,-1,-1)\n                if state[row][col] != \" \"])\n            for col in range(ncols)]\n\ndef print_stacks(stacks: list[deque])-> None:\n    \"\"\"Print a horizontally-oriented picture of stacks\"\"\"\n    N = max(len(row) for row in stacks)\n    pad = [\"  \"*(N - len(row)) for row in stacks]\n    for i, stack in enumerate(stacks):\n        print(f\"{(i+1)} {' '.join(stack)}{pad[i]}\")\n\n\n\nsource\n\n\nprint_stacks\n\n print_stacks (stacks:list[collections.deque])\n\nPrint a horizontally-oriented picture of stacks\n\nsource\n\n\nstackify\n\n stackify (state:list[list])\n\nConvert row-oriented input to compact stacks, top=right.\n\n\n\n\nType\nDetails\n\n\n\n\nstate\nlist\nCrate state in visual format\n\n\nReturns\nlist\nState as list of stacks, no blanks\n\n\n\n\n_ = [[' ', 'D', ' '],\n     ['N', 'C', ' '],\n     ['Z', 'M', 'P'],\n     ['1', '2', '3']]\n\nassert stackify(_) == [deque(['1', 'Z', 'N']), deque(['2', 'M', 'C', 'D']), deque(['3', 'P'])]\n\n\nstacks = stackify(state)\nprint_stacks(stacks)\n\n1 Z N  \n2 M C D\n3 P"
  },
  {
    "objectID": "day5.html#move-list",
    "href": "day5.html#move-list",
    "title": "day5",
    "section": "Move List",
    "text": "Move List\n\nsource\n\nprint_moves\n\n print_moves (moves:list[list[int]])\n\nVerbosely print a terse movelist.\n\nsource\n\n\nget_moves\n\n get_moves (rowdata:list[str])\n\nExtract move data from input\n\n\n\n\nType\nDetails\n\n\n\n\nrowdata\nlist\nAs from readlines\n\n\nReturns\nlist\n[[n, from_col, to_col], â€¦\n\n\n\n\nmoves = get_moves(start)\nprint_moves(moves)\n\nMove 1 from 2 to 1\nMove 3 from 1 to 3\nMove 2 from 2 to 1\nMove 1 from 1 to 2\n\n\nWhat is it to do a move? Line 1 moves the top crate D from stack 2 to stack 1. Iterated on these with some REPL. Quickly became clear I wanted state to be stacks so made a quick change to rotate the lists 90Âº and use deque. (Really could just use lists.)\nNote the -1 to correct for 0-indexing. Would be nicer to include a hidden stack 0 so we donâ€™t need that. Later.\n\n\nCode\ndef move(\n    n:    int|str,     # Move this many\n    from_col: int|str, # From this stack\n    to_col:   int|str, # To this stack\n    pos:  list,        # Position -> Will be CHANGED!\n    )-> None:\n    \"\"\"Move `n` crates from `from_col` to `to_col`. Modifies in place.\"\"\"\n    n, from_col, to_col = int(n), int(from_col), int(to_col)\n    for i in range(n):\n        move1box(pos[from_col - 1], pos[to_col - 1])\n\ndef move1box(\n    from_stack: deque, # From this stack\n    to_stack:   deque, # To this stack\n    )-> None:          # Modifies in place\n    \"\"\"Move 1 crates from `from_stack` to `to_stack`.\"\"\"\n    to_stack.append(from_stack.pop())\n\n\n\nsource\n\n\nmove1box\n\n move1box (from_stack:collections.deque, to_stack:collections.deque)\n\nMove 1 crates from from_stack to to_stack.\n\n\n\n\nType\nDetails\n\n\n\n\nfrom_stack\ndeque\nFrom this stack\n\n\nto_stack\ndeque\nTo this stack\n\n\nReturns\nNone\nModifies in place\n\n\n\n\nsource\n\n\nmove\n\n move (n:int|str, from_col:int|str, to_col:int|str, pos:list)\n\nMove n crates from from_col to to_col. Modifies in place.\n\n\n\n\nType\nDetails\n\n\n\n\nn\nint | str\nMove this many\n\n\nfrom_col\nint | str\nFrom this stack\n\n\nto_col\nint | str\nTo this stack\n\n\npos\nlist\nPosition -> Will be CHANGED!\n\n\nReturns\nNone\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nTook about 45min to get to this point with the first versions of move and move1box, then had to stop for work. Given how straightforward this is, Iâ€™m suprised how long it takes me - documenting, thinking, little iterations & tests.\n\n\n\nstacks = stackify(state)\nmove(2, 1, 2, stacks)\nstacks\n\n[deque([]), deque(['M', 'C', 'D', 'N', 'Z']), deque(['P'])]"
  },
  {
    "objectID": "day5.html#solve-example",
    "href": "day5.html#solve-example",
    "title": "day5",
    "section": "Solve Example",
    "text": "Solve Example\n\nAfter Step 1:\nShould be\n\nstep1 = \"\"\"\n[D]        \n[N] [C]    \n[Z] [M] [P]\n 1   2   3 \n \"\"\"\n\n\nstacks = stackify(state)\nmove(*moves[0], stacks)\nprint_stacks(stacks)\n\n1 Z N D\n2 M C  \n3 P    \n\n\nAfter Step 2:\n\nstep2 = \"\"\"\n        [Z]\n        [N]\n    [C] [D]\n    [M] [P]\n 1   2   3\n \"\"\"\n\n\nmove(*moves[1], stacks)\nprint_stacks(stacks)\n\n1         \n2 M C    \n3 P D N Z\n\n\nAfter Step 3:\n\nstep3 = \"\"\"\n        [Z]\n        [N]\n[M]     [D]\n[C]     [P]\n 1   2   3\n \"\"\"\n\n\nmove(*moves[2], stacks)\nprint_stacks(stacks)\n\n1 C M    \n2         \n3 P D N Z\n\n\nEnd, after Step 4:\n\nstep4 = \"\"\"\n        [Z]\n        [N]\n        [D]\n[C] [M] [P]\n 1   2   3\n \"\"\"\n\n\nmove(*moves[3], stacks)\nprint_stacks(stacks)\n\n1 C      \n2 M      \n3 P D N Z\n\n\nCrates on top are: [C] [M] [Z].\nAnswer would be CMZ.\n\n\nCode\ndef top_crates(stacks: list[deque]  # List of stacks\n              )-> str:              # Crates on top\n    \"\"\"Find the crates on top of each stack\"\"\"\n    return \"\".join(stack[-1] for stack in stacks)\n\n\n\nsource\n\n\ntop_crates\n\n top_crates (stacks:list[collections.deque])\n\nFind the crates on top of each stack\n\n\n\n\nType\nDetails\n\n\n\n\nstacks\nlist\nList of stacks\n\n\nReturns\nstr\nCrates on top\n\n\n\nTest that\n\nassert top_crates(stacks) == \"CMZ\""
  },
  {
    "objectID": "day5.html#get-the-data",
    "href": "day5.html#get-the-data",
    "title": "day5",
    "section": "Get the data",
    "text": "Get the data\n\nwith open(\"data/day5_input.txt\") as f:\n    data = [x.strip() for x in f.readlines()]\ndata[:3]\n\n['[B]                     [N]     [H]',\n '[V]         [P] [T]     [V]     [P]',\n '[W]     [C] [T] [S]     [H]     [N]']"
  },
  {
    "objectID": "day5.html#run",
    "href": "day5.html#run",
    "title": "day5",
    "section": "Run",
    "text": "Run\n\nstacks = stackify(get_state(data))\nfor _ in get_moves(data):\n    move(*_, stacks)\ntop_crates(stacks)\n\n'PSNRGBTFT'"
  },
  {
    "objectID": "day5.html#run-1",
    "href": "day5.html#run-1",
    "title": "day5",
    "section": "Run",
    "text": "Run\n\nstacks = stackify(get_state(data))\nfor _ in get_moves(data):\n    moveall(*_, stacks)\ntop_crates(stacks)\n\n'BNTZFPMMW'"
  },
  {
    "objectID": "template.html",
    "href": "template.html",
    "title": "day0",
    "section": "",
    "text": "The elves want something.\nThe input is â€¦"
  },
  {
    "objectID": "template.html#define-f-g",
    "href": "template.html#define-f-g",
    "title": "day0",
    "section": "Define f & g",
    "text": "Define f & g\n\n\nCode\ndef f():\n    pass\n\ndef g():\n    pass\n\n\n\nsource\n\ng\n\n g ()\n\n\nsource\n\n\nf\n\n f ()\n\n\n\nCode\ndef f(x: int,   # An x\n               y: int,   # A y\n              )-> str:   # An xy\n    \"\"\"Find the ....\"\"\"\n    return \"f\"\n\ndef g(x: int) -> None:\n    \"\"\"Find the ....\"\"\"\n    pass\n\n\n\nsource\n\n\ng\n\n g (x:int)\n\nFind the â€¦.\n\nsource\n\n\nf\n\n f (x:int, y:int)\n\nFind the â€¦.\n\n\n\n\nType\nDetails\n\n\n\n\nx\nint\nAn x\n\n\ny\nint\nA y\n\n\nReturns\nstr\nAn xy\n\n\n\n\nf(3,4)\ng(2)\n\nSay some more\n\n\nCode\n# Probably more defs here.\n\n\n\n_ = \"A simple example\"\n\nassert True    # Make a test"
  },
  {
    "objectID": "template.html#define-h",
    "href": "template.html#define-h",
    "title": "day0",
    "section": "Define h",
    "text": "Define h\n\nassert True\n\nThoughtsâ€¦\nNoteâ€¦\n\n\nCode\ndef h() -> str:\n    return \"What, another stub?\"\n\n\n\nsource\n\nh\n\n h ()\n\n\n\n\n\n\n\nNote\n\n\n\nIt took \\(x\\) minutes to get here. Or now weâ€¦ Or â€¦ something.\n\n\n\nh()\n\n'What, another stub?'"
  },
  {
    "objectID": "template.html#solve-example",
    "href": "template.html#solve-example",
    "title": "day0",
    "section": "Solve Example",
    "text": "Solve Example\n\nTest Case 1\nShould be\n\ntest1 = \"\"\"\nPaste a test case here\n\"\"\"\n\n\nh()\n\n'What, another stub?'\n\n\n\n\nTest Case 2\n\ntest2 = \"\"\"\nAnother\n\"\"\"\n\n\nh()\nh()\n\n'What, another stub?'\n\n\n\n\nFinal Test\nE.g.: Answer would be CMZ.\n\n\nCode\ndef get_answer(x: int,   # An x\n               y: int,   # A y\n              )-> str:   # An xy\n    \"\"\"Find the ....\"\"\"\n    return \"CMZ\"\n\n\n\nsource\n\n\nget_answer\n\n get_answer (x:int, y:int)\n\nFind the â€¦.\n\n\n\n\nType\nDetails\n\n\n\n\nx\nint\nAn x\n\n\ny\nint\nA y\n\n\nReturns\nstr\nAn xy\n\n\n\nTest that\n\nassert get_answer(3,1) == \"CMZ\""
  },
  {
    "objectID": "template.html#get-the-data",
    "href": "template.html#get-the-data",
    "title": "day0",
    "section": "Get the data",
    "text": "Get the data\n\ninput_name = f\"data/{NAME}_input.txt\"\nwith open(f\"data/{NAME}_input.txt\") as f:\n    data = [x.strip() for x in f.readlines()]\ndata[:3]\n\nFileNotFoundError: [Errno 2] No such file or directory: 'data/day0_input.txt'"
  },
  {
    "objectID": "template.html#run",
    "href": "template.html#run",
    "title": "day0",
    "section": "Run",
    "text": "Run\n\ng(data)"
  },
  {
    "objectID": "template.html#run-1",
    "href": "template.html#run-1",
    "title": "day0",
    "section": "Run",
    "text": "Run\n\nold = [3,4,5,6,7,8,9,10]\nnew = [1,2]\nbaz_the_foo(3, old, new)\nprint(old, new)\n\n\nFooter: nbdev magic"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  }
]